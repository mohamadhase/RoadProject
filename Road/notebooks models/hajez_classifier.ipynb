{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nasser\\.conda\\envs\\finall\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "import pandas as pd\n",
    "from constants import HAWAJEZ\n",
    "from utils.helpers import is_talking_about_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data_for_hajez_classifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text                0\n",
       "message_is_question      0\n",
       "reply_is_question        0\n",
       "is_giving_information    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "df.fillna('', inplace=True)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>message_is_question</th>\n",
       "      <th>reply_is_question</th>\n",
       "      <th>is_giving_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الدي سي اوه مشاكل ؟؟</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               full_text  message_is_question  reply_is_question  \\\n",
       "0   الدي سي اوه مشاكل ؟؟                    1                  0   \n",
       "\n",
       "   is_giving_information  \n",
       "0                      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hajez_name(row):\n",
    "    if row['is_giving_information'] == 0 :\n",
    "        return \"no_hajez\"\n",
    "    if row[\"message_is_question\"] == 1 : \n",
    "        return \"no_hajez\"\n",
    "    for hajez in HAWAJEZ:\n",
    "        if is_talking_about_it(row['full_text'], hajez):\n",
    "            return hajez\n",
    "    return \"no_hajez\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hajez_name'] = df.apply(get_hajez_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>message_is_question</th>\n",
       "      <th>reply_is_question</th>\n",
       "      <th>is_giving_information</th>\n",
       "      <th>hajez_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31010</th>\n",
       "      <td>شو وضع يستسهار؟؟</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>دير شرف سالكة؟</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28376</th>\n",
       "      <td>حدا ياكدلنا دير شرف انزل؟ لهسه دير شرف سالكة</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>دير شرف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>حاجز حواره مسكر</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>حوارة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70809</th>\n",
       "      <td>شو وضع صره للخارج ازمة وتفتيش</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>صره</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57029</th>\n",
       "      <td>حد عندو علم ايش اقتحام</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72198</th>\n",
       "      <td>فش اشي</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33268</th>\n",
       "      <td>اشي عزعتره واقفين جيش بنص شارع نمره ضفه بحولو ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39041</th>\n",
       "      <td>لمربعة</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63872</th>\n",
       "      <td>استنفار كبير لقوات الاحتلال حوارة</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_hajez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               full_text  message_is_question  \\\n",
       "31010                                   شو وضع يستسهار؟؟                    1   \n",
       "7708                                      دير شرف سالكة؟                    1   \n",
       "28376       حدا ياكدلنا دير شرف انزل؟ لهسه دير شرف سالكة                    0   \n",
       "7999                                     حاجز حواره مسكر                    0   \n",
       "70809                      شو وضع صره للخارج ازمة وتفتيش                    0   \n",
       "57029                             حد عندو علم ايش اقتحام                    0   \n",
       "72198                                             فش اشي                    1   \n",
       "33268  اشي عزعتره واقفين جيش بنص شارع نمره ضفه بحولو ...                    0   \n",
       "39041                                             لمربعة                    0   \n",
       "63872                  استنفار كبير لقوات الاحتلال حوارة                    0   \n",
       "\n",
       "       reply_is_question  is_giving_information hajez_name  \n",
       "31010                  0                      0   no_hajez  \n",
       "7708                   0                      0   no_hajez  \n",
       "28376                  0                      1    دير شرف  \n",
       "7999                   0                      1      حوارة  \n",
       "70809                  1                      1        صره  \n",
       "57029                  1                      1   no_hajez  \n",
       "72198                  0                      0   no_hajez  \n",
       "33268                  1                      0   no_hajez  \n",
       "39041                  0                      0   no_hajez  \n",
       "63872                  0                      0   no_hajez  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate, Input, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the Arabic text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['full_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['full_text'])\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the binary features\n",
    "binary_features = df[['message_is_question', 'reply_is_question', 'is_giving_information']].values\n",
    "\n",
    "# Prepare the target variable\n",
    "target = pd.get_dummies(df['hajez_name']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train_text, X_test_text, X_train_binary, X_test_binary, y_train, y_test = train_test_split(\n",
    "    padded_sequences, binary_features, target, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model\n",
    "embedding_dim = 100\n",
    "vocab_size = len(word_index) + 1\n",
    "num_classes = target.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layers\n",
    "text_input = Input(shape=(max_sequence_length,), dtype='int32', name='text_input')\n",
    "binary_input = Input(shape=(3,), dtype='float32', name='binary_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text processing layers\n",
    "text_embed = Embedding(vocab_size, embedding_dim, input_length=max_sequence_length)(text_input)\n",
    "text_lstm = Bidirectional(LSTM(256, return_sequences=True))(text_embed)\n",
    "text_lstm2 = Bidirectional(LSTM(256))(text_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate text features and binary features\n",
    "merged = Concatenate()([text_lstm2, binary_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output layer with dropout\n",
    "dropout = Dropout(0.5)(merged)\n",
    "output = Dense(num_classes, activation='softmax')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=[text_input, binary_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 41s 570ms/step - loss: 1.4399 - accuracy: 0.7020 - val_loss: 1.0199 - val_accuracy: 0.7288\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 35s 553ms/step - loss: 1.0666 - accuracy: 0.7360 - val_loss: 0.9213 - val_accuracy: 0.7667\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 35s 553ms/step - loss: 0.7607 - accuracy: 0.8059 - val_loss: 0.6634 - val_accuracy: 0.8327\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 35s 558ms/step - loss: 0.5565 - accuracy: 0.8504 - val_loss: 0.5526 - val_accuracy: 0.8578\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 35s 553ms/step - loss: 0.4059 - accuracy: 0.8907 - val_loss: 0.4504 - val_accuracy: 0.8882\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 35s 549ms/step - loss: 0.2904 - accuracy: 0.9214 - val_loss: 0.3779 - val_accuracy: 0.9107\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 35s 553ms/step - loss: 0.2091 - accuracy: 0.9422 - val_loss: 0.3734 - val_accuracy: 0.9148\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 35s 560ms/step - loss: 0.1656 - accuracy: 0.9540 - val_loss: 0.3242 - val_accuracy: 0.9237\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 35s 559ms/step - loss: 0.1285 - accuracy: 0.9647 - val_loss: 0.3262 - val_accuracy: 0.9257\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 34s 544ms/step - loss: 0.1060 - accuracy: 0.9703 - val_loss: 0.3328 - val_accuracy: 0.9298\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 34s 545ms/step - loss: 0.0914 - accuracy: 0.9742 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 34s 547ms/step - loss: 0.0771 - accuracy: 0.9780 - val_loss: 0.3248 - val_accuracy: 0.9314\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 35s 563ms/step - loss: 0.0695 - accuracy: 0.9800 - val_loss: 0.3396 - val_accuracy: 0.9254\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 35s 556ms/step - loss: 0.0660 - accuracy: 0.9806 - val_loss: 0.3278 - val_accuracy: 0.9308\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 34s 546ms/step - loss: 0.0603 - accuracy: 0.9824 - val_loss: 0.3390 - val_accuracy: 0.9310\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 34s 533ms/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.3296 - val_accuracy: 0.9313\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 34s 543ms/step - loss: 0.0530 - accuracy: 0.9847 - val_loss: 0.3216 - val_accuracy: 0.9347\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 35s 560ms/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.3384 - val_accuracy: 0.9323\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 34s 546ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.3508 - val_accuracy: 0.9302\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 35s 548ms/step - loss: 0.0455 - accuracy: 0.9863 - val_loss: 0.3402 - val_accuracy: 0.9323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f8971b408>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    {'text_input': X_train_text, 'binary_input': X_train_binary},\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=1024,\n",
    "    validation_data=({'text_input': X_test_text, 'binary_input': X_test_binary}, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/hajez_tokenizer.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "model.save('../models/hajez_classifier.h5')\n",
    "# save the tokenizer\n",
    "import joblib\n",
    "joblib.dump(tokenizer, '../models/hajez_tokenizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "Predicted category: صرة\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a new sample as follows:\n",
    "sample_text = \"  سالك سيبسي بسيب سيب سيبسش صرة\"\n",
    "sample_message_is_question = 0\n",
    "sample_reply_is_question = 0\n",
    "sample_is_giving_information = 1\n",
    "\n",
    "# Preprocess the text\n",
    "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
    "sample_padded_sequence = pad_sequences(sample_sequence, maxlen=max_sequence_length)\n",
    "\n",
    "# Preprocess the binary features\n",
    "sample_binary_features = np.array([[sample_message_is_question, sample_reply_is_question, sample_is_giving_information]])\n",
    "\n",
    "# Predict the category\n",
    "prediction = model.predict([sample_padded_sequence, sample_binary_features])\n",
    "\n",
    "# Get the index of the predicted category\n",
    "predicted_index = np.argmax(prediction)\n",
    "\n",
    "# Map the index to the correct category\n",
    "index_to_category = {index: category for index, category in enumerate(pd.get_dummies(df['hajez_name']).columns)}\n",
    "predicted_category = index_to_category[predicted_index]\n",
    "\n",
    "print(\"Predicted category:\", predicted_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_category = {index: category for index, category in enumerate(pd.get_dummies(df['hajez_name']).columns)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no_hajez',\n",
       " 1: 'الحمرا',\n",
       " 2: 'الطنيب',\n",
       " 3: 'العيزرية',\n",
       " 4: 'الفندق',\n",
       " 5: 'الكونتينر',\n",
       " 6: 'المربعه',\n",
       " 7: 'بيت ايل',\n",
       " 8: 'بيت فوريك',\n",
       " 9: 'بيتا',\n",
       " 10: 'تل',\n",
       " 11: 'جبع',\n",
       " 12: 'جيت',\n",
       " 13: 'حزما',\n",
       " 14: 'حوارة',\n",
       " 15: 'حومش',\n",
       " 16: 'دي سي او',\n",
       " 17: 'دير شرف',\n",
       " 18: 'زعترة',\n",
       " 19: 'سلمان',\n",
       " 20: 'شافي شمرون',\n",
       " 21: 'صرة',\n",
       " 22: 'صره',\n",
       " 23: 'عراق بورين',\n",
       " 24: 'عناتا',\n",
       " 25: 'عورتا',\n",
       " 26: 'عوفرا',\n",
       " 27: 'عين يبرود',\n",
       " 28: 'قرني شمرون',\n",
       " 29: 'قلنديا',\n",
       " 30: 'كدوميم ',\n",
       " 31: 'يتسهار'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_category"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
